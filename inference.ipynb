{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz6kS9QfH9x7bUGPIwx/UB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun29-git/translation_model/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Requirements\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Google Drive to load trained weights\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "zerm66zUM8JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Repo\n",
        "REPO_NAME = \"translation_model\"\n",
        "if not os.path.exists(f'/content/{REPO_NAME}'):\n",
        "    !git clone https://github.com/varun29-git/{REPO_NAME}\n",
        "sys.path.append(f'/content/{REPO_NAME}')"
      ],
      "metadata": {
        "id": "GgjzoksjNEYp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import build_transformer\n",
        "from config import get_config\n",
        "from train import greedy_decode, causal_mask"
      ],
      "metadata": {
        "id": "0ynKf608NaUf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get config and setup the device\n",
        "config = get_config()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IMzJiG9EOJRK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These tokenizers are the SAME ones used during training.\n",
        "tokenizer_src = Tokenizer.from_file(f\"/content/{REPO_NAME}/tokenizer_en.json\")\n",
        "tokenizer_tgt = Tokenizer.from_file(f\"/content/{REPO_NAME}/tokenizer_hi.json\")"
      ],
      "metadata": {
        "id": "Bn_DN1Z1PTDn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = build_transformer(\n",
        "    src_vocab_size=tokenizer_src.get_vocab_size(),\n",
        "    tar_vocab_size=tokenizer_tgt.get_vocab_size(),\n",
        "    src_seq_len=config[\"seq_len\"],\n",
        "    tar_seq_len=config[\"seq_len\"],\n",
        "    d_model=config[\"d_model\"],\n",
        "    N=config[\"N\"],\n",
        "    h=config[\"h\"],\n",
        "    d_ff=config[\"d_ff\"],\n",
        "    dropout=config[\"dropout\"]\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "14yQuP9aPVqY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/content/drive/MyDrive/Hindi_Translator_Project/t_model_24.pt\"\n",
        "\n",
        "# Weights import\n",
        "if os.path.exists(weights_path):\n",
        "    print(f\"Loading weights from {weights_path}...\")\n",
        "    checkpoint = torch.load(weights_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    print(\"Weights loaded\")\n",
        "else:\n",
        "    print(f\"Weights not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxMaTKZgPXZa",
        "outputId": "2ef4324a-1f79-47f5-c071-7a2cae0b46e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from /content/drive/MyDrive/Hindi_Translator_Project/t_model_24.pt...\n",
            "Weights loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert raw text into padded token IDs\n",
        "def encode_sentence(sentence, tokenizer, seq_len):\n",
        "    tokens = tokenizer.encode(sentence).ids\n",
        "    tokens = tokens[:seq_len - 2]\n",
        "\n",
        "    tokens = (\n",
        "        [tokenizer.token_to_id(\"[SOS]\")] +\n",
        "        tokens +\n",
        "        [tokenizer.token_to_id(\"[EOS]\")]\n",
        "    )\n",
        "\n",
        "    padding = [tokenizer.token_to_id(\"[PAD]\")] * (seq_len - len(tokens))\n",
        "    return torch.tensor(tokens + padding).unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "IPMSUFXzTqna"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def translate(sentence):\n",
        "    model.eval()\n",
        "\n",
        "    # Encode source sentence\n",
        "    src = encode_sentence(\n",
        "        sentence,\n",
        "        tokenizer_src,\n",
        "        config[\"seq_len\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # Source padding mask\n",
        "    src_mask = (src != tokenizer_src.token_to_id(\"[PAD]\")) \\\n",
        "        .unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # Greedy decoding\n",
        "    output_tokens = greedy_decode(\n",
        "        model,\n",
        "        src,\n",
        "        src_mask,\n",
        "        max_len=config[\"seq_len\"],\n",
        "        device=device,\n",
        "        tokenizer_src=tokenizer_src,\n",
        "        tokenizer_tar=tokenizer_tgt\n",
        "    )\n",
        "\n",
        "    # Decode tokens to text and clean special symbols\n",
        "    return tokenizer_tgt.decode(output_tokens.tolist()) \\\n",
        "        .replace(\"[SOS]\", \"\") \\\n",
        "        .replace(\"[EOS]\", \"\") \\\n",
        "        .strip()"
      ],
      "metadata": {
        "id": "PSs7ZIwITwIl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common conversational sentences translate best\n",
        "print(translate(\"How are you doing today?\"))\n",
        "print(translate(\"Do you know who I am?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHPYIrG0TyGB",
        "outputId": "02553144-26bc-46ea-82fe-43386ed9f828"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "आज तुम क्या कर रहे हो ?\n",
            "क्या तुम जानते हो कि मैं कौन हूँ ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proper nouns perform weaker due to limited representation in training data.\n",
        "print(translate(\"My name is Varun\"))\n",
        "print(translate(\"I am a writer\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Udo0hMCT52p",
        "outputId": "06e8d008-1c7c-42ad-8e70-9791bc89964c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मेरा नाम है\n",
            "मैं 5 करता हूँ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrates out-of-distribution behavior\n",
        "print(translate(\"Namaste\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIdMBxBjU4sq",
        "outputId": "6a48cef3-c6dc-4bad-9152-568f28f9ed2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". kgm\n"
          ]
        }
      ]
    }
  ]
}